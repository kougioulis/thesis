\section{Epilogue \& Final Thoughts} \label{sec:epilogue}

%As this thesis comes to a close, it is tempting to view its pages as a finished story: Chapters written, contributions laid out, results measured and compared. Yet, like all stories in science, it is less an ending than a turning point; a comma rather than a full stop. 

Our journey began with a simple question: can we create a foundation model on the dance of time-series, to uncover the hidden strings of causality that govern examined data? How can this be achieved without the need for re-training on each independent data input? Along the way, we wandered through the importance of causal assumptions, the complexity of real-world data, and the black-box beauty of deep learning. Each of these contributions, felt at times like bricks in a cathedral still under construction: each one necessary, yet incomplete on its own. Together, they form a sturdy ground on which future contributions may build higher.

To this end, much remains to be explored. Questions left unanswered remain as important as those addressed. In the end, as large language models continue to rise in prominence, their limitations in causal reasoning highlight a parallel challenge: models that excel at pattern recognition but lack causal understanding risk producing contextually plausible yet logically unsound outputs. If causality is essential for LLMs, then LCMs represent an analogous step for temporal data: embedding causal reasoning at the very core of time-series modeling. \\

\begin{chapquote}{\citet{wu2024causality}}
``While LLMs excel at tasks involving language understanding, generation, and pattern recognition, they often struggle with tasks that require deeper causal reasoning. Without an understanding of causality, LLMs may produce outputs that are contextually relevant but not logically sound, leading to potential issues such as hallucinations, biased outputs, and an inability to perform well on decision-making tasks that depend on causal relationships. Incorporating causality into LLMs is essential for several reasons.''
\end{chapquote}