\section{Generation of Interventional Samples} \label{sec:data-interventions}

So far our discussion concerned generation of temporal SCMs and observational data from their causal structure. As introduced methodologies (Sections \ref{sec:data-synthetic} and \ref{sec:data-simulated}) output causal models. From these causal models, observational data are then generated. The final pillar of data generation concerns the creation of interventional samples. As elaborated in Chapter \ref{chap:problem-formulation}, an intervention \( \text{do}(V^i_t) = x_t\) corresponds to replacing the functional dependency of \(V^i_t\) in the time-lagged SCM at timestep \(t\) with \( V^i_t := x_t\), in the case of a hard intervention and \( V^i_t := f(\text{Pa}(V^i_t), \epsilon_{V^i}) + x_t \) in the case of a soft intervention. The general method for performing anestral sampling in the TSCM to obtain interventions is illustrated in Algorithm \ref{alg:scm-interventional-sampling}.  

\begin{algorithm}[h]
\caption{Temporal SCM Interventional Sampling (INTERVENTION)}
\label{alg:scm-interventional-sampling}
\begin{algorithmic}[1]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\REQUIRE Temporal Causal Graph $\mathcal{G}$, number of timesteps $T$, max lag $\ell_{\max}$, number of warmup steps $W$, intervention probability $p_{\text{int}} \in [0,1]$, variable-wise value ranges $\mathcal{R} = \{[v_i^{\min}, v_i^{\max}]\}_{i=1}^N$
\ENSURE Interventional time-series sample $\{\mathbf{X}_t\}_{t=1}^{T}$, intervention mask $\mathbf{B} \in \{0,1\}^{T \times N}$
\STATE Initialize $X^i_0$ for all $i \in \{1, \dots, N\}$ with random noise
\STATE Initialize intervention mask $\mathbf{B} \gets \mathbf{0} \in \{0,1\}^{T \times N}$
\FOR{$t = W + \ell_{\max} + 1$ to $T$}
    \FOR{each variable $X^i_t$}
        \IF{Bernoulli$(p_{\text{int}}) = 1$}
            \STATE Sample intervention value $x^i_{\text{int}} \sim \mathcal{U}(v_i^{\min}, v_i^{\max})$
            \STATE Set $X^i_t \gets x^i_{\text{int}}$
            \STATE Set $B_{t,i} \gets 1$
        \ELSE
            \STATE Determine lagged parents:
            \STATE \hspace{1em} $\text{Pa}(X^i_t) \gets \{X^j_{t-k} \mid (X^j, X^i) \in \mathcal{G},\; 1 \leq k \leq \ell_{\max}\}$
            \STATE Compute $X^i_t \gets f_i(\text{Pa}(X^i_t)) + \epsilon^i_t$
        \ENDIF
    \ENDFOR
\ENDFOR
\RETURN $\{\mathbf{X}_t\}_{W+\ell_{\max}}^{T}$, $\mathbf{B}$
\end{algorithmic}
\end{algorithm}

In this work, data collections containing interventions are performed by hard interventions, uniformly sampled from the observational domain of each variable, i.e. \( v^i \sim \mathcal{U}(V_i^{\min}, V_i^{\max})\). Such sampling is performed at each generated timestep and thus accounts for multiple interventional targets. The purpose of the above is two-fold: First, it ensures that interventions remain realistic and within the natural range of the variables, avoiding extreme or implausible values that could distort the dynamics or violate the underlying causal constraints. Second, it promotes diversity and coverage in the interventional data themselves, allowing the model to observe and learn causal effects across the full suport of each variable's distribution. 

Each of these interventional samples is also paired with a \textit{binary intervention mask}, which indicates which variables were intervened on at each timestep. Formally, the mask is \( \mathbf{B} \in \{0,1\}^{T \times N} \), where \( B_{t,i} = 1 \) if variable \( X^i \) was intervened on at timestep \(t\), and \(B_{t,i} = 0\) otherwise. This formulation accounts for both single as well as multiple interventional targets. This does not only serve as a way to test performance of LCMs when training with interventional data as well, but also provide important information for a possible meta-analysis of these data, as an important component of the generation pipeline. The way interventional samples along with the intervention mask are handled by LCMs in particular is explained in Chapter \ref{chap:architecture}.