\section{Generating Simulated  Pairs} \label{sec:data-simulated}

In contrast to synthetic data, simulated (realistically generated) data aim to reflect the underlying causal dynamics of real-world systems by reverse-engineering the structural and functional dependencies from actual time-series. Essentially, we address the problem of generating time-series data from a causal model with the same distribution as a given real dataset, that is, constructing a probabilistic causal digital twin. 

For this purpose, we introduce the \textit{Temporal Causal-based Simulation (TCS)} framework, a modular and model-agnostic generative \footnote{A generative model is a type of machine learning model designed to learn the underlying probability distribution of a dataset and is therefore capable of generating new, synthetic data samples that are statistically and structurally similar to the training data.} method for generating time-series along with their temporal causal graphs, which incorporates a fine-tuning process for optimal model selection called \textit{Adversarial Causal Tuning (ACT)}. Generated data is not only statistically coherent but also maintains interpretable causal consistency, making it suitable for training and benchmarking of our Large Causal Models.

Ideally, what one is looking for is the ability to generate data that is both realistic and comparable to real-world cases, and as such a way to discrimimate between simulated data of good and poor quality. In literature, there exist various methods for asserting whether two data samples resemble each other. One way to measure similarity between (observed) real and synthetic data is by the \textit{Maximum Mean Discrepancy (MMD)} \citep{gretton2006kernel} metric. MMD measures the distance between two probability distributions by embedding the data into a reproducing kernel inner-product space and calculating the difference in the mean embeddings. The MMD score is given by \(\text{MMD}^2(X, Y) = \mathbb{E}_{X, X}[k(X, X)] + \mathbb{E}_{Y, Y}[k(Y, Y)] - 2\mathbb{E}_{X, Y}[k(X, Y)]\), where \(X\) and \(Y\) are the real and synthetic data samples respectively and the expectations are taken over all points in the selected data batch. 

A more useful way to assess data similarity is using \textit{Classifier 2-sample tests (C2STs)}. The main idea behind C2STs, introduced by \citet{gretton2012kernel}, is to train a machine learning classifier \(f_\theta\) to distinguish samples \(X=\left\{x_1,\ldots,x_n\right\} \) sampled from distribution \(P\) against samples \(Y = \left\{y_1,\ldots,y_m\right\}\) sampled from distribution \(Q\). Intuitively, if the null hypothesis \(H_0: P = Q\) holds, then the classifier (trained on the labeled training set \(\mathcal{D} = \left\{ (x_i, 0)\right\} \cup \left\{ (y_j, 1)\right\}\)) should be unable to distinguish between samples and should demonstrate performance close to \(1/2\), or chance level when evaluated on a holdout test set. By performance, we refer to the AUC-ROC score of the classifier \citep{bradley1997use}, to which we refer to as \textit{discrimimation score} \(\mathrm{AUC}_D\). As \citet{lopez2017revisiting} demonstrated, classifier 2-sample tests offer several attractive properties for evaluating data similarity, such as assessing the quality of samples generated by models where the likelihood is intractable (cannot be computed analytically) but sampling from the generating process is tractable.

To highlight our contributions in realistic data generation, we present key arguments against the suitability of the work by \citet{cheng2024causaltime} for training and evaluating our LCMs. It remains the closest to our work, in the sense that it is applicable to time-series and has been introduced as a method to benchmark causal discovery algorithms. However, it faces several shortcomings. It begins by fitting a residual-based neural network (\textit{causally disentangled neural network - CDNN}), based on either an MLP or an LSTM architecture, to model a \textit{vector autoRegressive (VAR)} process, using all historical variables for a specified maximum lag; it then extracts a \textit{hypothetical causal graph (HCG)} based on computed feature importance values, using methods such as deep Shapley additive exPlanations (DeepSHAP) \citep{lundberg2017unified}, while being able to generate data auto-regressively from the fitted model. As the authors themselves point out throughout their paper, the extracted HCG using feature importance does not constitute causal discovery and does not represent a causal model. As such, causal queries are not possible and the discovered graph does not represent a causal digital twin. As their extracted hypothetical causal graph represents a \textit{summary graph} with no lag information and not a \textit{lagged causal graph} (Figure \ref{fig:temporal-graphs}), its scope remains limited. Additionally, although a generative mechanism for data exists by the fitted model, it does not reflect or approximate the underlying TSCM mechanism. Consequently, generation of interventional samples is unfeasible: the resulting process may generate temporally correlated samples, but not reason causally, e.g. to estimate \(P(Y|\text{do}(X=x))\). 

\begin{figure}[ht!]
    \centering
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=0.99\linewidth]{images/figures/t-a.png}
        \label{fig:tsne-a}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=0.99\linewidth]{images/figures/t-b.png}
        \label{fig:tsne-b}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=0.99\linewidth]{images/figures/t-c.png}
        \label{fig:tsne-c}
    \end{minipage}

    \vspace{15pt}

    \caption{t-SNE \citep{maaten2008visualizing} projections of original and simulated data across different datasets. Optimized C2ST variants outperform standard methods (e.g., MMD) in detecting distributional differences, even when visual separability is low.}
    \label{fig:tsne}

    \vspace{15pt}
\end{figure}

Furthermore, CausalTime relies on a single discriminator to evaluate its simulation quality in addition to the MMD metric. As shown in Figure \ref{fig:tsne} leads to misleading conclusions about the quality of generated data. Data are projected in the plane using t-SNE \citep{maaten2008visualizing}, and the discriminator is trained to distinguish between real and generated data. In Figure \ref{fig:tsne} (a), only the support vector classifier (SVC)-based C2ST is able to distinguish simulated from original samples, which have been generated using trigonometric functions. The other two C2STs, based on logistic regression (LR) and long-short-term memory (LSTM) are unable to do so, with an \(\mathrm{AUC}_D\) of \(0.52\) and \(0.61\) respectively. A similar experimental scenario is shown in Figure \ref{fig:tsne} (b) on the \texttt{AirQualityUCI} dataset where an optimized\footnote{An optimized classifier refers to a model whose hyperparameters or configuration are tuned to maximize its performance (e.g., \(\mathrm{AUC}_D\)), whereas an unoptimized classifier uses default or untuned parameters.} LSTM classifier discriminates, while the unoptimized one fails. Finally, Figure \ref{fig:tsne} (c) reveals the inadequacy of the maximum mean discrepancy metric, as although it is close to zero and data seem indistinguishable with the naked eye, an optimized LSTM classifier is still able to separate them. Consequently, the need for introducing a causal model generator by utilizing optimized C2STs is clear.

\subsection{Temporal Causal-based Simulation (TCS)} \label{subsec:tcs}

This subsection is dedicated to the main generative method for producing realistic time-series data and their respective time-lagged causal graph, called \textit{Temporal Causal-based Simulation (TCS)}, depicted in Figure \ref{fig:pipeline-part-a}. Our method can be summarized briefly by the following statement: \textit{Select the model that generates simulated data which, despite our best efforts, are indistinguishable from the real training data}. By best efforts, we refer to the fine-tuning phase. We summarize the formulation as follows: (i) a \textit{Generation phase}, where a module performs a search in the space of causal models by generating TSCMs and (ii) a \textit{Tuning phase}, where another module searches the space of discriminators to distinguish between real and simulated data, called \textit{Adversarial Causal Tuning (ACT)}. The above procedure leads to a Min-max selection scheme, similarly to generative adversarial networks (GANs) \citep{goodfellow2014generative}. We now describe the main phases of the TSCM search space and ACT.

\begin{figure}[tbp]
    \centering
    \includegraphics[width=\textwidth]{images/figures/pipeline_aaa.png}
    \caption{
        Given a multivariate time-series sample of real data, the method begins by estimating the lagged causal graph through temporal causal discovery (\textit{Phase 1}). It then estimates the functional dependencies between variables using a wide range of forecasters (\textit{Phase 2}). Based on the predictions of these forecasters, it learns the noise distribution through a variety of density estimation methods (\textit{Phase 3}). Each combination of methods for Phases 1, 2 and 3 constitutes a configuration for TCS, that results in a unique \textit{temporal causal model}. By considering different configurations, TCS creates a search space for the temporal causal model that best describes the real data.
    }
    \label{fig:pipeline-part-a}
\end{figure}

\subsubsection{Generation of TSCMs}

\paragraph{Phase 1: Causal Discovery}

Initially, TCS retrieves the data's causal structure. To achieve this, the method employs a variety of causal discovery methods for temporal data, either established as a gold standard or express the current state-of-the-art. Specifically, we consider the algorithms \textit{PCMCI} \citep{runge2018causal} and \textit{DYNOTEARS} \citep{pamfil2020dynotears}. PCMCI is a CD method based on conditional independence testing, serving as a temporal extension of PC \citep{spirtes2001causation} established through literature, while DYNOTEARS constitutes an extension of the NOTEARS \citep{zheng2018dags} CD algorithm on temporal data, based on continuous optimization. These methods are also used as benchmarks for evaluating our trained LCMs and are discussed in detail at Section \ref{sec:baselines}.

We now describe the generation of TSCMs with some mathematical rigor. Given a multivariate time-series dataset \( \mathcal{D} \) over \( \mathbf{V} \), the first phase performs temporal causal discovery using an CD algorithm dependent on a given parameter configuration \( \mathbf{B}_\text{CD} \) (e.g. for DYNOTEARS, the regularization constants \( \lambda_\mathbf{W}, \lambda_\mathbf{A} \in \mathbf{B}_\text{CD} \)). That is, obtain: 

\begin{equation}\label{eq:phase-cd}
\mathcal{G}, \left\{ \mathbf{Pa}_{X^i} \right\}_{i \in \mathbf{V}} \leftarrow \text{CAUSAL\_ALG}(\mathcal{D}, \mathbf{B}_\text{CD})
\end{equation}

It is crucial to highlight that the outcome of all the considered time-series CD methods are \textit{lagged causal graphs}, that not only serve as an expressive representation of the causal model for training our LCMs, but also able to preserve the temporal structure of data for further use. We describe TCS in Algorithm \ref{alg:tcs}. It should also be noted that as causal discovery algorithms are governed by a set of causal assumptions, sampled data from TCS, as well as input data to the method, are assumed to follow these assumptions. The algorithms and their assumptions are selected to align with the causal assumptions of our LCMs, in Chapter \ref{chap:architecture}. 

\begin{algorithm}[t]
\caption{Temporal Causal-Based Simulation (TCS-SIMULATE)}
\label{alg:tcs}
\begin{algorithmic}[1]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\REQUIRE Real time-series dataset $\mathcal{D} = \{\mathbf{X}_t\}_{t=1}^{T}$ over variable set $\mathbf{V}$; sample size $n$; causal discovery configs $\{\mathbf{B}_{CD}\}$; functional dependency estimator configs $\{\mathbf{B}_{pred}\}$; noise estimation configs $\{\mathbf{B}_{noise}\}$; ACT parameters $(D, \{C_d\}, \alpha, n_{perm})$
\ENSURE Optimal causal model $s_{\text{best}}$, generated dataset $\mathcal{D}'_{s_{\text{best}}}$, and discriminator score $\mathrm{AUC}_{\text{best}}$
\STATE $\mathcal{S} \gets \text{GENERATE\_TSCM\_CONFIG\_SPACE}(\{\mathbf{B}_{CD}\}, \{\mathbf{B}_{pred}\}, \{\mathbf{B}_{noise}\})$
\STATE $\mathcal{R} \gets \emptyset$
\FOR{each configuration $s \in \mathcal{S}$}
    \STATE Obtain $\mathbf{b}_{CD}$, $\mathbf{b}_{pred}$, $\mathbf{b}_{noise}$ from $s$
    \STATE $(\mathcal{G}_s, \mathbf{Pa}_s) \gets \text{CAUSAL\_ALG}(\mathcal{D}, \mathbf{b}_{CD})$ \COMMENT{Phase 1: Causal discovery}
    \STATE Initialize $\mathcal{F}_s \gets \emptyset$, $\mathcal{E}_s \gets \emptyset$
    \FOR{each variable $X^i \in \mathbf{V}$}
        \IF{$\mathbf{Pa}_{X^i} \neq \emptyset$}
            \STATE $f_{X^i} \gets \text{FIT}(X^i, \mathbf{Pa}_{X^i}, \mathbf{b}_{pred})$
            \STATE $R_{X^i} \gets X^i - f_{X^i}(\mathbf{Pa}_{X^i})$
        \ELSE
            \STATE $R_{X^i} \gets X^i - \mathbb{E}[X^i]$
        \ENDIF
        \STATE $\mathcal{F}_s \gets \mathcal{F}_s \cup \{f_{X^i}\}$
    \ENDFOR
    \FOR{each variable $X^i \in \mathbf{V}$}
        \STATE $\epsilon^i \gets \text{FIT}(R_{X^i}, \mathbf{b}_{noise})$
        \STATE $\mathcal{E}_s \gets \mathcal{E}_s \cup \{\epsilon^i\}$
    \ENDFOR
    \STATE $\mathcal{D}'_s \gets \text{ANCESTRAL}(\mathcal{G}_s, \mathcal{F}_s, \mathcal{E}_s, n, T)$ \COMMENT{Ancestral sampling}
    \STATE $\mathcal{R} \gets \mathcal{R} \cup \{(s, \mathcal{G}_s, \mathcal{F}_s, \mathcal{E}_s, \mathcal{D}'_s)\}$
\ENDFOR
\STATE $(s_{\text{best}}, \mathrm{AUC}_{\text{best}}) \gets \text{ACT}(\mathcal{S}, \mathcal{D}, D, \{C_d\}, \alpha, n_{perm})$
\RETURN $s_{\text{best}}, \mathcal{D}'_{s_{\text{best}}}, \mathrm{AUC}_{\text{best}}$
\end{algorithmic}
\end{algorithm}


\paragraph{Phase 2: Estimation of Functional Dependencies} 

After the causal structure of the data has been retrieved, we estimate the functional dependencies between variables by fitting forecasting methods on the past (lagged) parent values of each variable. We incorporate three model options for the forecasting task. The first consists of classic \textit{Random Forest} (RF) \citep{breiman2001random} models on lagged data representations according to the maximum discovered time lag \(\ell_\text{max}\) during the fist phase of the algorithm. The second option incorporates the \textit{AD-DSTCN}, a 1-D Convolutional forecaster utilized by \citet{nauta2019causal} in their proposed TCDF method. The last addition to our forecaster options is the TimesFM foundation model for time-series forecasting, introduced by \citet{das2024decoder}. Considering the time-series \(X^i\), we now apply (or fit) a predictive model \(f\) on its lagged parents \(\text{Pa}_{X^i}\), to obtain an approximation of the functional dependency as in the SCM formulation. Mathematically, 

\begin{equation}\label{eq:phase-fr}
f(X^i \mid \text{Pa}_{X^i}) \gets \text{FIT}(X^i, \text{Pa}_{X^i}, \mathbf{B}_\text{pred})
\end{equation}

where \(\text{FIT}\) corresponds to the predictive algorithm used. Like in the causal discovery phase, \(\mathbf{B}_\text{pred}\) is the algorithm-dependent parameter configuration. We depict the set of the fitted functional dependencies for each node as \(\mathcal{F}\).

\begin{table}[t]
\centering
\caption{Search spaces for TSCMs and Discriminators (C2STs).} \label{tab:search-spaces}
\scriptsize
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{5pt}

\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Method} & \textbf{Hparam} & \textbf{Values} \\
\midrule
\multicolumn{3}{c}{\textbf{(a) TSCM Search Space}} \\
\midrule
\multirow{2}{*}{PCMCI \citep{runge2018causal}}
    & n\_lags & \{2, 3\} \\
    & n\_reps & \{10\} \\

\midrule
\multirow{6}{*}{DYNOTEARS \citep{pamfil2020dynotears}}
    & n\_lags & \{1, 3\} \\
    & $\lambda_w$, $\lambda_a$ & \{0.1\} \\
    & max\_iter & \{100\} \\
    & n\_reps & \{10\} \\
    & Thresholded / Threshold & \{True / 0.05\} \\

\midrule
DENSE (FC Baseline) & Graph Type & Fully Connected \\

\midrule
\multirow{1}{*}{Random Forest \citep{breiman2001random}}
    & n\_estimators & \{100, 500, 1000\} \\

\midrule
\multirow{4}{*}{AD-DSTCN (TCDF) \citep{nauta2019causal}}
    & num\_levels & \{0, 2\} \\
    & epochs & \{1000\} \\
    & kernel\_size / dilation\_c & \{(2,2), (3,3)\} \\
    & lr & \{0.01, 0.001\} \\

\midrule
TimesFM \citep{das2024decoder} & Model Type & Foundational Forecaster \\

\midrule
Noise Models & noise\_approx. & \{\texttt{est}, \texttt{normal}, \texttt{uniform}, \texttt{spline}, \texttt{nvp}\} \\

\midrule
\multicolumn{3}{c}{\textbf{(b) Discriminator (C2ST) Search Space}} \\
\midrule

\multirow{4}{*}{SVM}
    & C & \{1.0, 0.75, 0.5, 0.25\} \\
    & Kernel & \{\texttt{linear}, \texttt{poly}, \texttt{rbf}\} \\
    & Degree & \{3\} \\
    & Gamma & \{\texttt{auto}, \texttt{scale}\} \\

\midrule
\multirow{7}{*}{LSTM}
    & Batch Size & \{32, 64\} \\
    & Hidden Size & \{128, 256\} \\
    & Layers & \{2, 3\} \\
    & Dropout & \{0.05, 0.1\} \\
    & Seq. Len & \{10, 20\} \\
    & Epochs & \{10, 50\} \\
    & LR & \{0.0001, 0.001\} \\

\bottomrule
\end{tabular}
\end{table}

\paragraph{Phase 3: Estimation of Noise Distribution}

The estimation of functional dependencies is followed by the estimation of the true noise distribution for each variable. The predictions of the fitted forecasting models are utilized to obtain the residual terms by subtracting the real data values of the corresponding time-steps. In case a variable at hand has no deduced causal parents from Phase 1, a trivial predictor can be used, as the mean of the observed values, a solution dependent on the assumption of time-series stationarity. The result of this process corresponds to the empirical distribution of the noise, which is then utilized along additional noise estimation methods. That is, for a variable \( X_i \) and a noise configuration \(\mathbf{B}_\text{noise}\), fit the noise estimator \(\epsilon_i \leftarrow \text{FIT}(\mathbf{B}_\text{noise})\).

Additionally, we also consider two neural approaches for the estimation of the noise distribution. These consists of Neural Spline Flows \citep{durkan2019neural} and a simplistic version of the RealNVP model \citep{dinh2016density}. Finally, a known parametric distribution for the noise of the data is utilized (e.g., Normal) and the empirical noise distribution is used to fit its parameters (e.g., mean and variance). The set of all fitted noise estimators for each node is depicted as \(\mathcal{E}\).

Table \ref{tab:search-spaces} provides an overview of the implemented methods for each phase, along with their hyperparameter configurations. Their successive application results in the creation of a TSCM \((\mathcal{G}, \mathcal{F}, \mathcal{E})\), consisting of the discovered causal structure \( \mathcal{G}\) (\textit{phase 1}), functional dependencies \( f^i \in \mathcal{F}\) (\textit{phase 2}) and noise distributions \( \epsilon^i_t \in \mathcal{E}\) (\textit{phase 3}), all of which are derived from the provided original time-series using the selected methods per phase. We now describe the methodology for obtaining the optimal configuration of the TSCM that best fits the original data through ACT.


\subsection{Adversarial Causal Tuning (ACT) \label{subsec:adversarial_causal_tuning}}

\begin{figure}[tbp]
    \centering
    \includegraphics[width=\textwidth]{images/figures/pipeline_bbb_sp2.png}
    \caption{%
        Inspired by AutoML practices and the adversarial learning paradigm of GANs, TCS leverages C2ST as discriminators to assess the quantitated temporal causal models. Each causal model generates synthetic data, which are discriminated against the real data by a robust AutoML pipeline of C2ST models. TCS returns the causal model with the \textit{minimum} discrimination score (\(\mathrm{AUC}_D\)) against the \textit{maximum} performance discriminator.
    }
    \label{fig:pipeline-part-b}
\end{figure}

We leverage on the multiple available options per phase during the TSCM generation, to create a search space \(C\) for the optimal configuration of TCS. At its highest capacity, this search space consists of all possible unique combination of methods (adjusting also for different hyperparameter settings) for all three phases, resulting in the creation of thousands of candidate temporal causal models. To adjust for running efficiency, we restrict the possible simulation configurations to orders of magnitude of tens. To identify the causal model that best describes the original data, each created instance must be assessed based on the similarity of its sampled data empirical distribution to the empirical distribution of the original data. 

Recall that concerning the use of complex parameterized evaluation methods such as C2STs, hyperparameter configuration plays a significant role, especially in case of high-dimensional data with complex functional dependencies (e.g., Figure \ref{fig:tsne}). In general, different metrics may prove to have independent behavior, especially in high dimensions, as shown in \citet{goudet2018learning}. Inspired by the AutoML \citep{hutter2019automated} domain, a configurable discriminator search space is created, with a grid-based search performed to find the C2ST that bests discriminates between generated and original data.

The classifiers that we consider as possible C2ST discriminators include the \textit{Support Vector Classifier (SVC)} \citep{hearst1998support} and the \textit{Long Short-Term Memory-based Classifier (LSTMC)} \citep{hochreiter1997long}, both optimized though hyperparameter tuning \citep{hutter2019automated}, in order to obtain the discriminator that yields the highest \(\mathrm{AUC}_D\). 

By running this process for each candidate causal model, we thus avoid underfit discrimination. This approach highly resembles a discreet, non-differentiable version of adversarial learning in GANs \citep{goodfellow2014generative}, as both the temporal SCM and the discriminator are optimized in parallel while competing with each other. The C2ST problem is deduced to a Min-max selection scheme as follows: Define a set of classifiers \(D\), each with a set of configurations \( C_d = \left\{ c_{d,1}, c_{d,2}, \ldots, c_{d,n} \right\} \). For each classifier \(d \in D\) and configuration \(c \in C_d\), we compute the discriminative score \(d_c\) of the classifier. From these configurations, the maximum discriminative score is selected across the set of lowest scores. That is, optimize with Min-max selection as \[\displaystyle \min_{c \in C} \max_{d \in D} d_c \] The maximization step can be interpreted as \textit{"For each TSCM configuration \(c\), obtain the highest discriminative score across the classifiers"}, while the minimization step as \textit{"Among all TSCM configurations, select the configuration with the lowest maximum score, which depicts the least discriminative, yet optimal case"}. 

In the end, TCS returns the configuration of the optimal temporal causal model, along with the discrimination score and the optimized configuration of the discriminator. This is shown in Figure \ref{fig:pipeline-part-b}, and in pseudocode form in Algorithm \ref{alg:act}.  The considered hyperparameter search spaces for the classifiers (adversarial space) are shown in Table \ref{tab:search-spaces}.

\begin{algorithm}[t]
\caption{Adversarial Causal Tuning (ACT)}
\label{alg:act}
\begin{algorithmic}[1]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\REQUIRE Candidate TCS configurations $\mathcal{S} = \{s_1, \dots, s_m\}$; real test set $\mathcal{D}$; discriminator space $D$; discriminator configuration grids $\{C_d\}_{d \in D}$; significance level $\alpha$; number of permutations $n_{perm}$
\ENSURE Optimal TCS configuration $s_{\text{best}}$ and discrimination score $\mathrm{AUC}_{\text{best}}$
\STATE $\mathcal{R} \gets \emptyset$ \COMMENT{Store best discriminator result for each TCS configuration}
\FOR{each configuration $s \in \mathcal{S}$}
    \STATE $\mathcal{D}'_s \gets \text{SIMULATE}(s)$ \COMMENT{Generate dataset via TCS}
    \STATE $\mathrm{AUC}^s_{\text{best}} \gets -\infty$, $\text{Disc}^s_{\text{best}} \gets \text{None}$, $\text{Cfg}^s_{\text{best}} \gets \text{None}$
    \FOR{each discriminator $d \in D$}
        \FOR{each configuration $c \in C_d$}
            \STATE $\mathrm{AUC}^{c}_{d} \gets \text{TRAIN\_EVAL}(d, c, \mathcal{D}, \mathcal{D}'_s)$
            \IF{$\mathrm{AUC}^{c}_{d} > \mathrm{AUC}^s_{\text{best}}$}
                \STATE $\mathrm{AUC}^s_{\text{best}} \gets \mathrm{AUC}^{c}_{d}$
                \STATE $\text{Disc}^s_{\text{best}} \gets d$
                \STATE $\text{Cfg}^s_{\text{best}} \gets c$
            \ENDIF
        \ENDFOR
    \ENDFOR
    \STATE $\mathcal{R} \gets \mathcal{R} \cup \{(s, \mathrm{AUC}^s_{\text{best}}, \text{Disc}^s_{\text{best}}, \text{Cfg}^s_{\text{best}})\}$
\ENDFOR
\STATE Select configuration $s_o \in \mathcal{R}$ with the lowest $\mathrm{AUC}^s_{\text{best}}$
\STATE Retrieve associated $\text{Disc}_o, \text{Cfg}_o, \mathrm{AUC}_o$
\STATE $\mathcal{E} \gets \{s_o\}$ \COMMENT{Set of statistically equivalent configurations}
\FOR{each configuration $s \in \mathcal{R} \setminus \{s_o\}$}
    \STATE Obtain $probs_o, probs_s, \mathrm{AUC}_o, \mathrm{AUC}_s$ from their discriminators
    \STATE $p \gets \text{PERM\_TEST}(y_{\text{test}}, probs_o, probs_s, \mathrm{AUC}_o, \mathrm{AUC}_s, \alpha, n_{perm})$
    \IF{$p \ge \alpha$}
        \STATE $\mathcal{E} \gets \mathcal{E} \cup \{s\}$ \COMMENT{Add statistically equivalent configuration}
    \ENDIF
\ENDFOR
\STATE $s_{\text{best}} \gets$ configuration in $\mathcal{E}$ with fewest edges in its causal graph
\RETURN $s_{\text{best}}, \mathrm{AUC}^{s_{\text{best}}}_{\text{best}}$
\end{algorithmic}
\end{algorithm}


\subsubsection{Sparsity Penalty}

A drawback of the proposed method is that it may occasionally favor dense graph outputs to more realistic candidate solutions of phase 1, being statistically beneficial during the next phases. To avoid this, we adopt a \textit{sparsity penalty strategy} following \citet{biza2022oct}. Specifically, a permutation-based statistical hypothesis test is introduced on whether two classifiers have statistically equivalent scores. The permutation test assumes as null-hypothesis that two given classifiers have statistically equivalent \(\mathrm{AUC}_D\) scores and uses as its statistic the difference between these two discriminative scores. At its core, the permutation test swaps the per sample predicted probabilities of two classifiers and then re-calculates and compares the permuted outcomes to the ground-truth. If the \(p-\text{value}\) computed by the permutation test is larger than the significance level \(\alpha\), then the comparing \(\mathrm{AUC}_D\)s are considered equivalent. By default, a significance level of \(\alpha=0.05\) and 1000 permutations is used to compute the \(p-\text{value}\). It should be noted that no significant computational overhead is introduced with sparsity penalty, as the only operations performed is the swapping of predictions and the calculation of the permuted \(\mathrm{AUC}_D\) scores. Detailed steps are described in Algorithm \ref{alg:statistical-equivalence-test}. Through this, candidate causal models from the TSCM search space that are statistically equivalent to the best-performing one are filtered. All such candidate models are compared against their sparsity, with the sparsest one being selected, thus avoid the problem of favoring the trivial solution of dense graphs during the search for the optimal causal model.

\begin{algorithm}[t]
\caption{AUC Statistical Equivalence Test (PERM\_TEST)}
\label{alg:statistical-equivalence-test}
\begin{algorithmic}[1]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\REQUIRE Test set labels $y_{\text{test}}$; discriminator test predicted probabilities on the optimal TCSM output $probs_{o}$; discriminator test predicted probabilities on a candidate TCSM output $probs_{i}$; discrimination scores $\mathrm{AUC}_o$ and $\mathrm{AUC}_i$; significance level $\alpha$; number of permutations $n_{perm}$
\ENSURE \textit{True} or \textit{False} for statistical equivalence
\STATE $t_{obs} \gets |\mathrm{AUC}_{o} - \mathrm{AUC}_{i}|$
\STATE $ctr \gets 0$
\FOR{$p = 1$ to $n_{perm}$}
    \STATE $w^{p}_{l} \gets \text{SAMPLE\_PERMUTATION\_INDICES()}$ \COMMENT{Sample indices to swap uniformly}
    \STATE $(probs^{o}_{w}, probs^{i}_{w}) \gets \text{SWAP}(probs_{o}, probs_{i}, w^{p}_{l})$ \COMMENT{Permute sampled indices}
    \STATE $\mathrm{AUC}_{o}^{w} \gets \text{EVALUATE}(y_{\text{test}}, probs^{o}_{w})$
    \STATE $\mathrm{AUC}_{i}^{w} \gets \text{EVALUATE}(y_{\text{test}}, probs^{i}_{w})$
    \STATE $t_{p} \gets |\mathrm{AUC}_{o}^{w} - \mathrm{AUC}_{i}^{w}|$
    \IF{$t_{p} > t_{obs}$}
        \STATE $ctr \gets ctr + 1$
    \ENDIF
\ENDFOR
\STATE $pvalue \gets \frac{ctr}{n_{perm}}$
\IF{$pvalue \ge \alpha$}
    \STATE \textbf{return} True
\ELSE
    \STATE \textbf{return} False
\ENDIF
\end{algorithmic}
\end{algorithm}


\subsection{Evaluation of Simulation Quality} \label{sec:sim-results}

In this section, the capabilities of the proposed \textit{ACT} mechanism are evaluated across two main axes: (i) the ability to accurately recover causal structures from temporal data and (ii) the capacity to simulate realistic temporal dynamics across synthetic and real-world cases. These evaluation experiments aim to assess the robustness of ACT in causal discovery and its competitiveness in temporal data generation against both causal\footnote{Although it has been discussed that CausalTime is not based on a causal model, it is placed in this category for our comparison due to its context.} and non-causal baselines.

The main evaluation metrics for these experiments are: (i) the \textit{Structural Hamming Distance (SHD)} \citep{tsamardinos2006max} for assessing causal structure discovery, computed betweeen the estimated and ground-truth graphs. SHD quantifies the number of graph operations (edge additions, deletions, or reversals) required to match the true graph, where a lower value indicates higher structural accuracy. A reversal accounts for two operations, while a deletion or addition for one. This metric is used to evaluate TCS in Figure \ref{fig:sparsity_penalty}. (ii) \textit{Adjacency-based AUC}, notated \(\mathrm{AUC}_{adj}\). Following \citet{cheng2024causaltime} and \citet{stein2024embracing}, we compute an AUC score based on adjacency matrices of predicted and ground-truth DAGs. The predicted adjacency probabilities are thresholded to \(\tau=0.05\) and compared against the true structure; both matrices are flattened before computing their AUC. This score evaluates the ML efficacy of learned causal structures and is distinct from the sample-level discrimination score \(\mathrm{AUC}_D\) introduced previously.

\subsubsection{Evaluation of the Estimated Causal Structure} \label{subsubsec:sparsity_experiment}

To assess the ability of ACT to correctly infer causal relationships, we generate synthetic datasets with varying levels of complexity. Each dataset consists of ten (10) variables, modeled as an additive noise TSCM with non-linear functional dependencies and Gaussian noise. The underlying causal graphs differ in edge density, ranging from three (3) to thirty (30) edges, thus simulating increasing structural difficulty. These datasets are generated as elaborated in Section \ref{sec:data-synthetic}. Two experimental scenarios are considered: (i) \textit{Fully Connected Candidate Graphs} and \textit{Oracle Ground Truth Candidate Graphs}. 

The first setup examines whether ACT avoids the trivial fully-connected causal structure when such a configuration is included in the search space. Nineteen (19) synthetic datasets are analyzed \textit{(C1)}, each processed by ACT both \textit{with} and \textit{without} the sparsity penalty term. Our results indicate that the sparsity-regularized runs successfully avoided the trivial fully connected solution in all 19 cases, while 8 out of 19 non-regularized runs incorrectly selected it, especially in the case of denser graphs (more than 10 edges). This demonstrates the critical role of sparsity regularization in guiding ACT toward parsimonious causal graphs.

In the second setup, the true causal graph is included as a candidate solution (oracle) in Phase 1, to test whether ACT is able to recover it correctly. With sparsity penalty enabled, ACT successfully identifies the correct causal graph in 16 out of 19 cases (\(\text{SHD}=0\)). Without the sparsity penalty, the true structure is recovered in only 8 out of 19 cases. However, even in mismatched cases, the estimated graphs exhibit low SHD scores, indicating that our method is able to recover solutions that are close to the ground truth. 

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{images/figures/sparsity_penalty_random_v3.png}
    (a) \hspace{6.5cm} (b)
    \hfill
    \caption{\textbf{(a)}: Parallel calls of TCS with (w/) and without (w/o) the sparsity penalty, while providing a fully-connected lagged causal graph (referred as \textit{dense graph}) in the \(1^{st}\) phase outputs. The selected causal graphs are compared to the ground truth through SHD, where low SHD scores mean the graphs resemble each other. Calls with sparsity penalty successfully avoid the fully connected graph as a candidate solution at all cases. On the other hand, calls without sparsity penalty end up selecting the fully connected graph 8 out of 19 times, especially for denser cases with 11 or more edges in the ground truth. \textbf{(b)}: Parallel calls of TCS with and without the sparsity penalty, while providing the ground-truth as an oracle lagged causal graph in the \(1^{st}\) phase outputs. Similarity measured through SHD, as in (a). In the vast majority of 16 out of 19 cases, calls with the sparsity penalty successfully chose the oracle graph as the optimal solution. In contrast, calls without the sparsity penalty were able to identify the oracle graph only in 7 out of 19 cases. The results in both (a) and (b) establish the sparsity penalty as a necessary part of TCS.}
    \label{fig:sparsity_penalty}
\end{figure*}

\subsubsection{Comparison to the State-of-the-Art} \label{subsubsec:sim-comparison}

Next, we evaluate the ability of ACT to generate realistic temporal data perform a comparison against both causal and non-causal simulation approaches. The considered methods are (i) \textit{CausalTime} \citep{cheng2024causaltime}, a predictive-modeling-based simulator that captures feature importance but does not perform explicit causal discovery, (ii) \textit{CPAR} \citep{zhang2022sequential}, a conditional probabilistic auto-regressive generative model implemented within the \textit{SDV} framework \citep{patki2016synthetic} and (iii) \textit{TimeVAE} \citep{desai2021timevae}, a variational autoencoder model for time-series generation, implemented via the \textit{SynthCity} library \citep{qian2023synthcity}.

All considered methods are evaluated on both synthetic and real-world datasets, created in accordance with Section \ref{sec:data-training}. For each dataset, 2000-sample sequences are drawn using a block bootstrap approach \citep{gonccalves2011discussion,hardle2003bootstrap}, repeated 10 times in order to compute standard errors. Additionally, the preprocessing protocol of \citep{cheng2024causaltime} is adopted, including linear interpolation for missing values. It should be once more noted that a comparison is inherently unfair, as causal simulation faces a much complex task: ACT generates complete Temporal Structural Causal Models (TSCMs), while CausalTime and other baselines operate at the correlation level without any causal interpretability.

\begin{table}[h!]
\centering
\caption{Benchmarks against non-causal simulation: Comparison of TCS/ACT against causal (CausalTime) and non-causal (CPAR, TimeVAE) simulation methods. Despite solving a more complex causal task, ACT achieves comparable discrimination scores (\(\mathrm{AUC}_D\)) across datasets, often outperforming CausalTime. Lower \(\mathrm{AUC}_D\) values (in \textcolor{red}{red}) indicate more realistic simulations.}
\vspace{8pt}
\setlength{\tabcolsep}{4pt}
\begin{tabular}{lcccc}
\toprule
\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{4}{c}{\textbf{Method}} \\
\cmidrule(lr){2-5}
 & \textbf{TCS (ACT)} & \textbf{CausalTime} & \textbf{CPAR} & \textbf{TimeVAE} \\
\midrule
WTH & $0.85 {\scriptscriptstyle{\pm 0.01}}$ & $0.80 {\scriptscriptstyle{\pm 0.00}}$ & $0.99 {\scriptscriptstyle{\pm 0.00}}$ & $0.98 {\scriptscriptstyle{\pm 0.00}}$ \\
AirQualityUCI & $0.99 {\scriptscriptstyle{\pm 0.01}}$ & $0.83 {\scriptscriptstyle{\pm 0.00}}$ & $0.99 {\scriptscriptstyle{\pm 0.00}}$ & $0.95 {\scriptscriptstyle{\pm 0.00}}$ \\
AirQualityMS & $0.97 {\scriptscriptstyle{\pm 0.00}}$ & $0.84 {\scriptscriptstyle{\pm 0.00}}$ & $0.98 {\scriptscriptstyle{\pm 0.00}}$ & $0.99 {\scriptscriptstyle{\pm 0.00}}$ \\
ETTh1 & $0.92 {\scriptscriptstyle{\pm 0.00}}$ & $0.80 {\scriptscriptstyle{\pm 0.00}}$ & $0.95 {\scriptscriptstyle{\pm 0.00}}$ & $0.91 {\scriptscriptstyle{\pm 0.00}}$ \\
ETTm1 & $0.93 {\scriptscriptstyle{\pm 0.00}}$ & $0.82 {\scriptscriptstyle{\pm 0.00}}$ & $0.96 {\scriptscriptstyle{\pm 0.00}}$ & $0.91 {\scriptscriptstyle{\pm 0.00}}$ \\
Bike Usage & $0.88 {\scriptscriptstyle{\pm 0.01}}$ & $0.77 {\scriptscriptstyle{\pm 0.00}}$ & $0.90 {\scriptscriptstyle{\pm 0.00}}$ & $0.83 {\scriptscriptstyle{\pm 0.00}}$ \\
Outdoors & $0.99 {\scriptscriptstyle{\pm 0.00}}$ & $0.83 {\scriptscriptstyle{\pm 0.00}}$ & $0.99 {\scriptscriptstyle{\pm 0.00}}$ & $0.81 {\scriptscriptstyle{\pm 0.00}}$ \\
\midrule
$f$MRI & \textcolor{red}{\textbf{0.71}} ${\scriptscriptstyle{\pm 0.01}}$ & $0.78 {\scriptscriptstyle{\pm 0.01}}$ & \textcolor{red}{\textbf{0.74}} ${\scriptscriptstyle{\pm 0.02}}$ & $0.75 {\scriptscriptstyle{\pm 0.00}}$ \\
%Finance & $0.99 {\scriptscriptstyle{\pm 0.00}}$ & $0.78 {\scriptscriptstyle{\pm 0.00}}$ & $0.99 {\scriptscriptstyle{\pm 0.00}}$ & $0.86 {\scriptscriptstyle{\pm 0.00}}$ \\
C1 & \textcolor{red}{\textbf{0.57}} ${\scriptscriptstyle{\pm 0.00}}$ & $0.77 {\scriptscriptstyle{\pm 0.00}}$ & \textcolor{red}{\textbf{0.63}} ${\scriptscriptstyle{\pm 0.01}}$ & $0.81 {\scriptscriptstyle{\pm 0.00}}$ \\
\bottomrule
\end{tabular}
\label{tab:non-causal}
\end{table}

Despite addressing the challenging task of causal data generation, ACT achieves \(\mathrm{AUC}_D\) values on par with or better than purely statistical generators, especially on synthetic and semi-synthetic datasets. While non-causal models such as CPAR and TimeVAE focus solely on reproducing correlations, ACT is unique in its ability to produce a complete TSCM. As such, although causal data generation remains a challenging task, our proposed framework remains competitive while being the only approach that returns the estimated TSCM from data. 

A shortcoming of using the Min-max search scheme of ACT, together with the sparsity penalty when attempting to generate hundreds of thousands of instances for training an LCM model is the significant computational overhead. For instance, considering three options for causal discovery, five for functional relationship estimation and two for noise estimator (not taking into account any configurable hyperparameters of each method), this would result in generating a search space of 30 configurations, from which one would select a single data instance. This greatly reduces the amount of training pairs one is able to generate, thus deeming it inefficient for our end scope regarding training pair generation for LCMs. It remains however a significant contribution of this work towards realistic causal data generation itself, as well as for curating datasets for benchmarking causal discovery algorithms. 