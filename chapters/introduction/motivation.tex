\section{Motivation} \label{sec:motivation}

The field of causal discovery has undergone an important paradigm shift with the introduction of deep learning-based approaches. A landmark contribution is the NOTEARS paper by \citet{zheng2018dags}, which recast causal discovery as a continuous optimization scheme with acyclicity constraint, by relaxing the combinatorial nature of the problem. This opened the door to a whole class of differentiable causal discovery methods. In the i.i.d. setting, this led to the introduction of works such as DECI \citep{geffner2024deep}, AVICI \citep{lorch2022amortized} and CSIvA \citep{ke2023learning}, which leverage modern deep neural architectures and approaches to infer causal structure from data. Various works for temporal (time-series) data soon followed, with methods such as TCDF \citep{nauta2019causal}, ACD \citep{lowe2022amortized} and Rhino \citep{gong2023rhino} among others. \citet{assaad2022survey} and \citet{deng2022deep} provide a self-contained review on works for temporal causal discovery, for the interested reader.

Despite their promise, existing approaches face a number of limitations. Classical causal discovery methods for time-series based on conditional independence testing, such as PCMCI \citep{runge2018causal}, suffer from scalability issues due to the exponential number of independence tests required. While these methods are provably sound if infinite sample size is available \citep{spirtes2001causation}, they often fail to generalize in reduced, finite-sample regimes. Score-based methods, which search over graph structures using data likelihood or other criteria, such as DYNOTEARS \citep{pamfil2020dynotears}, can underperform when functional dependencies are complex or nonlinear, on the advantage of faster convergence (as linearity of causal relationships is assumed). Importantly, all of these methods operate on a single input-output pair at a time, which limits their ability to learn from multiple samples and causal graphs of varying sizes, complexities and dynamics. As a result, the challenge of building causal discovery methods that generalize across data distributions and promise high scalability to realistic time-series scenarios remains unresolved.

Meanwhile, the rise of \textit{foundation models} has revolutionized several domains of machine learning. In a nutshell, a foundation model (FM) refers to a pre-trained neural model, trained on large corpuses of data \citep{bommasani2021opportunities}. In natural language processing, the introduction of BERT \citep{devlin2019bert} marked a turning point by demonstrating the power of pretraining Transformer-based \citep{vaswani2017attention} models on massive data corpora, in the context of text translation. Previous works, being reliant on recurrent neural networks (RNNs), have been proven limited by design, in contrast to the Transformer architecture which has efficiently transformed the field of NLP. This was followed by the GPT family, culminating in models like GPT-4 \citep{achiam2023gpt}, which use hundreds of billions of parameters to support robust zero-shot\footnote{The ability of a model to generalize to data that has not been included in training, i.e. does not follow the distribution of the training data.} generalization \citep{radford2018improving, radford2019language}. Foundation models have also emerged in vision and multimodal learning, e.g. CLIP \citep{radford2021learning} and DALL-E \citep{ramesh2021zero}, exhibiting remarkable generalization across diverse downstream tasks. A unifying principle behind these models is that \textit{massive pretraining on varied data can lead to robust representations and inference capabilities without any task-specific supervision}. Recent work has extended this idea to time-series forecasting. Models such as TiMeR and TiMeR-XL \citep{liu2024timer} adopt decoder-only Transformer architectures to autoregressively model temporal sequences. MOIRAI \citep{woo2024unified} uses a masked encoder and patch-based input for forecasting, with model sizes ranging from 14M to 311M parameters. Google's TimesFM \citep{das2024decoder} follows a similar patch-based decoder design, with a 200M parameter footprint. These models demonstrate strong \textit{out-of-distribution (OOD)}\footnote{Performance on datasets that do not follow the distribution of the training data, also known as \textit{zero-shot} in the context of foundation models.} forecasting capabilities, suggesting that general-purpose foundation models for temporal data are viable. An overview of these foundation models, along with their sizes, is shown in Table \ref{tab:model-sizes}. 
 
\begin{table}[ht!]
\centering
\caption{Comparison of foundation model sizes across NLP and time-series forecasting domains.}
\label{tab:model-sizes}
\renewcommand{\arraystretch}{1.3}
\small
\begin{tabular}{|l|c|c|}
\hline
\textbf{Model} & \textbf{Domain} & \textbf{Parameters} \\
\hline
BERT \citep{devlin2019bert} \scriptsize{(Base)} & NLP & 108M \\
GPT-1 & NLP & 117M \\
%GPT-3.5 & NLP & 175B \\
%GPT-4 (est.) & NLP & \(\sim\)1.7T \\
\hline
Timer \citep{liu2024timer} & Time-series Forecasting & 84M\footnote{Model weights available at \url{https://huggingface.co/thuml/timer-base-84m}.} \\
MOIRAI \scriptsize{(Small / Base / Large)} \citep{woo2024unified} & Time-series Forecasting & 14M / 91M / 311M \\
TimesFM \citep{das2024decoder} & Time-series Forecasting & 200M\footnote{Model weights available at \url{https://huggingface.co/google/timesfm-1.0-200m}.} \\
\hline
\end{tabular}
\end{table}

Our work aims to extend this line of research towards causal discovery for time-series data. The concept of \textit{Large Causal Models (LCMs)} envisions a class of deep, pre-trained neural architectures specifically designed for temporal causal discovery. These models are trained on a diverse corpus of multivariate time-series sequences, paired with their corresponding ground-truth structural causal models, with a single aim: \textit{learning robust universal representations capable of performing zero-shot temporal causal discovery with refined lag estimation from arbitrary time-series samples} (Figure \ref{fig:lcm-goal}).

Unlike existing temporal state-of-the-art methods, which are often constrained to small numbers of variables and suffer from significant performance degradation as input dimensionality and model size increases, we showcase robust generalization of our LCMs across varying numbers of variables, time-series lengths, and temporal dynamics. By leveraging both synthetic and \textit{simulated} (realistically generated) datasets, our models aim to capture universal causal structures that are robust across domains, time scales, and data distributions. Moreover, causal discovery using LCMs is performed via a single forward pass over input data, making it significantly faster and scalable than traditional approaches, opening the door for real-time applications such as causal digital twins for decision-making and control.

Constructing foundation models for causal discovery raises several central challenges. First, input dimensionality (as in all pre-trained models) must be carefully considered: the maximum number of variables and timesteps directly impacts both feasibility and generalization. Inputs that are too small limit applicability, while overly large inputs may hurt performance. Second, training data quality and diversity are crucial. While existing approaches rely solely on synthetic data generated from arbitrary SCMs \citep{stein2024embracing}, purely synthetic datasets fail to capture the full complexity of real-world processes. To make matters worse, the availability of ground-truth causal structures from the real-world is scarce to non-existent. \textit{Semi-synthetic data}, based on existing knowledge of real scenarios (such as physical models or approximations of them by stochastic dynamical systems) can offer a pragmatic compromise, but a principled methodology for generating high-quality, diverse, and realistic SCM time-series pairs at scale remains a key open challenge; one which we address in Chapter \ref{chap:data}.

\begin{figure}[ht!]
\centering
\begin{tikzpicture}[>=Latex,thick]
  % Nodes (absolute, compact layout)
  \node[draw, align=center, minimum width=2.1cm, minimum height=0.9cm] (in)  at (0,0) {Time-series};
  \node[draw, align=center, minimum width=2.6cm, minimum height=1.4cm] (lcm) at (3.2,0) {\textbf{Pre-trained}\\ \textbf{LCM}};
  \node[draw, align=center, minimum width=2.1cm, minimum height=0.9cm] (out) at (6.4,0) {Causal Graph};

  % Arrows
  \draw[->] (in) -- (lcm);
  \draw[->] (lcm) -- (out);
\end{tikzpicture}
\caption{A pre-trained Large Causal Model (LCM) infers a causal graph from an unknown time-series data sequence. (Training uses thousands of pairs of time-series and their corresponding ground-truth causal graphs.)}
\label{fig:lcm-goal}
\end{figure}